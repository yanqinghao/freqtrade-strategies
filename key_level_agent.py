import os
import json
import re
from typing import List, Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from pydantic import BaseModel, Field, validator


class TradingSignal(BaseModel):
    """Trading signal with entry and exit points."""

    direction: str = Field(description="Trading direction: 'long' or 'short'")
    entry_points: List[float] = Field(description='List of entry price points, sorted')
    exit_points: List[float] = Field(description='List of target/exit price points, sorted')
    stop_loss: float = Field(description='Stop loss price level')
    risk_reward: Optional[float] = Field(None, description='Risk-reward ratio if available')

    @validator('direction')
    def validate_direction(cls, v):
        if v not in ['long', 'short']:
            raise ValueError(f"Direction must be 'long' or 'short', got {v}")
        return v

    @validator('entry_points')
    def validate_entry_points(cls, v):
        if not v:
            raise ValueError('Entry points list cannot be empty')
        return sorted(v)

    @validator('exit_points')
    def validate_exit_points(cls, v, values):
        if not v:
            raise ValueError('Exit points list cannot be empty')

        # Sort based on direction
        direction = values.get('direction')
        if direction == 'long':
            return sorted(v)  # For long positions, targets are ascending
        else:
            return sorted(v, reverse=True)  # For short positions, targets are descending


class TradingSignalExtractor:
    """
    Simple agent to extract trading signals from analysis text and convert to JSON
    """

    def __init__(self, api_key: Optional[str] = None, model_name: str = 'gpt-3.5-turbo'):
        """
        Initialize the Trading Signal Extractor

        Args:
            api_key: OpenAI API key (will use environment variable if not provided)
            model_name: Name of the language model to use
        """
        # Use provided API key or get from environment
        llm_api_key = os.environ['LLM_API_KEY']
        llm_base_url = os.environ['LLM_BASE_URL']
        llm_model_name = os.environ['LLM_MODEL_NAME']
        self.llm = ChatOpenAI(
            temperature=0.1, model_name=llm_model_name, base_url=llm_base_url, api_key=llm_api_key
        )

        # Define the extraction prompt template
        self.extraction_template = """
        You are a trading signal extraction specialist. Extract ONLY the short-term and medium-term trading signals from the following analysis text:
        <context>
        {text}
        </context>

        Output ONLY a JSON array in the following format:
        [
            {{
                "timeframe": "short" or "medium",
                "direction": "long" or "short",
                "entry_points": [array of entry price numbers, sorted from low to high for long, high to low for short],
                "exit_points": [array of target/exit price numbers, sorted from low to high for long, high to low for short],
                "stop_loss": stop loss price number,
                "risk_reward": risk/reward ratio number (optional)
            }}
        ]

        Rules:
        1. ONLY include short-term and medium-term signals (ignore long-term signals)
        2. For short-term signals: focus on 15-minute and 1-hour timeframes
        3. For medium-term signals: focus on 4-hour timeframe
        4. Entry points should include all mentioned entry prices as numbers
        5. Exit points should include all target prices as numbers
        6. For long positions: sort entry_points and exit_points from lowest to highest
        7. For short positions: sort entry_points and exit_points from highest to lowest
        8. Include risk_reward only if it's explicitly mentioned

        Parse all numbers as floating point values, not strings. Respond with ONLY the JSON array.
        """

        self.prompt = PromptTemplate(input_variables=['text'], template=self.extraction_template)

        # Create the extraction chain
        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)

    def gen_json_prompt(self, text: str) -> str:
        """Generate the JSON prompt for the given text"""
        return self.prompt.format(text=text)

    def extract_signals(self, text: str) -> List[Dict[str, Any]]:
        """
        Extract trading signals from analysis text

        Args:
            text: Technical analysis text

        Returns:
            List of dictionaries containing trading signals
        """
        try:
            # Process the text through the LLM chain
            response = self.chain.run(text=text)
            # Extract the JSON string from the response
            json_str = self._extract_json_from_response(response)

            # Parse the JSON
            if json_str:
                try:
                    parsed_data = json.loads(json_str)

                    # Handle both single-object and list responses
                    if isinstance(parsed_data, dict):
                        signals = [parsed_data]
                    elif isinstance(parsed_data, list):
                        signals = parsed_data
                    else:
                        raise ValueError(f"Unexpected JSON structure: {type(parsed_data)}")

                    # Validate each signal
                    valid_signals = []
                    for signal in signals:
                        try:
                            validated = TradingSignal(**signal)
                            valid_signals.append(validated.dict())
                        except Exception as e:
                            print(f"Validation error for signal: {e}")

                    return valid_signals
                except json.JSONDecodeError as e:
                    print(f"JSON parse error: {e}")
                    # Fall back to regex extraction if JSON parsing fails
                    return self._fallback_extract(text)
            else:
                # Fall back to regex extraction if no JSON found
                return self._fallback_extract(text)

        except Exception as e:
            print(f"Error extracting signals: {e}")
            return self._fallback_extract(text)

    def _extract_json_from_response(self, response: str) -> str:
        """
        Extract JSON string from LLM response

        Args:
            response: LLM response string

        Returns:
            Cleaned JSON string or empty string if not found
        """
        # Look for JSON structure with or without code blocks
        json_match = re.search(r'```(?:json)?(.*?)```', response, re.DOTALL)

        if json_match:
            # JSON was in a code block
            return json_match.group(1).strip()

        # Try to find JSON without code blocks
        # Look for brackets enclosing the entire response
        if response.strip().startswith('[') and response.strip().endswith(']'):
            return response.strip()

        # Try to find any JSON array in the response
        json_match = re.search(r'(\[.*\])', response, re.DOTALL)
        if json_match:
            return json_match.group(1).strip()

        return ''

    def _fallback_extract(self, text: str) -> List[Dict[str, Any]]:
        """
        Fallback method to extract trading signals using regex patterns

        Args:
            text: Technical analysis text

        Returns:
            List of dictionaries containing trading signals
        """
        results = []

        # Determine if long signal is present
        long_present = bool(re.search(r'åšå¤š|bullish|long|buy|ä¹°å…¥|ä¹°|çœ‹æ¶¨', text.lower()))

        # Determine if short signal is present
        short_present = bool(re.search(r'åšç©º|bearish|short|sell|å–å‡º|å–|çœ‹è·Œ', text.lower()))

        # Extract direction(s)
        directions = []
        if long_present and short_present:
            # Check if one is more emphasized
            long_emphasis = len(re.findall(r'åšå¤š|bullish|long|buy|ä¹°å…¥|ä¹°|çœ‹æ¶¨', text.lower()))
            short_emphasis = len(re.findall(r'åšç©º|bearish|short|sell|å–å‡º|å–|çœ‹è·Œ', text.lower()))

            if long_emphasis > short_emphasis * 1.5:
                directions = ['long']
            elif short_emphasis > long_emphasis * 1.5:
                directions = ['short']
            else:
                directions = ['long', 'short']
        elif long_present:
            directions = ['long']
        elif short_present:
            directions = ['short']
        else:
            # Default to long if direction is unclear
            directions = ['long']

        # Process each direction
        for direction in directions:
            # Initialize signal structure
            signal = {
                'direction': direction,
                'entry_points': [],
                'exit_points': [],
                'stop_loss': None,
            }

            # Extract entry points
            entry_patterns = [
                r'å…¥åœº.*?(\d+\.\d+)',
                r'å…¥åœºä»·æ ¼.*?(\d+\.\d+)',
                r'entry.*?(\d+\.\d+)',
                r'å…¥åœº.*?(\d+\.\d+[â€“-]\d+\.\d+)',
            ]

            for pattern in entry_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    if 'â€“' in match or '-' in match:
                        # Handle price ranges
                        parts = re.split(r'[â€“-]', match)
                        for part in parts:
                            try:
                                signal['entry_points'].append(float(part.strip()))
                            except ValueError:
                                continue
                    else:
                        try:
                            signal['entry_points'].append(float(match.strip()))
                        except ValueError:
                            continue

            # Extract exit points
            exit_patterns = [
                r'ç›®æ ‡.*?(\d+\.\d+)',
                r'target.*?(\d+\.\d+)',
                r'æ­¢ç›ˆ.*?(\d+\.\d+)',
                r'tp.*?(\d+\.\d+)',
                r'profit.*?(\d+\.\d+)',
            ]

            for pattern in exit_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    try:
                        signal['exit_points'].append(float(match.strip()))
                    except ValueError:
                        continue

            # Extract stop loss
            stop_loss_patterns = [r'æ­¢æŸ.*?(\d+\.\d+)', r'stop.*?(\d+\.\d+)', r'sl.*?(\d+\.\d+)']

            for pattern in stop_loss_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    try:
                        signal['stop_loss'] = float(match.group(1).strip())
                        break
                    except ValueError:
                        continue

            # Extract risk/reward ratio
            rr_patterns = [
                r'é£é™©æ”¶ç›Šæ¯”.*?(\d+(?:\.\d+)?)',
                r'risk[/\-]reward.*?(\d+(?:\.\d+)?)',
                r'r:r.*?(\d+(?:\.\d+)?)',
                r'rr.*?(\d+(?:\.\d+)?)',
            ]

            for pattern in rr_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    try:
                        signal['risk_reward'] = float(match.group(1).strip())
                        break
                    except ValueError:
                        continue

            # Ensure we have required fields with valid values
            if signal['entry_points'] and signal['exit_points']:
                # Sort appropriately
                if direction == 'long':
                    signal['entry_points'] = sorted(signal['entry_points'])
                    signal['exit_points'] = sorted(signal['exit_points'])
                else:
                    signal['entry_points'] = sorted(signal['entry_points'], reverse=True)
                    signal['exit_points'] = sorted(signal['exit_points'], reverse=True)

                # Generate stop loss if not found
                if signal['stop_loss'] is None and signal['entry_points']:
                    if direction == 'long':
                        signal['stop_loss'] = min(signal['entry_points']) * 0.95
                    else:
                        signal['stop_loss'] = max(signal['entry_points']) * 1.05

                results.append(signal)

        return results

    def consolidate_signals(self, signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Consolidate multiple signals of the same direction into optimized signals

        Args:
            signals: List of extracted trading signals

        Returns:
            Consolidated list of trading signals
        """
        if not signals:
            return []

        # Group signals by direction
        long_signals = [s for s in signals if s['direction'] == 'long']
        short_signals = [s for s in signals if s['direction'] == 'short']

        consolidated_signals = []

        # Consolidate long signals
        if long_signals:
            # For long positions, use lowest entry and lowest exit
            all_entries = [entry for signal in long_signals for entry in signal['entry_points']]
            all_exits = [
                exit_point for signal in long_signals for exit_point in signal['exit_points']
            ]
            all_stops = [
                signal['stop_loss'] for signal in long_signals if signal['stop_loss'] is not None
            ]

            if all_entries and all_exits and all_stops:
                best_long = {
                    'direction': 'long',
                    'entry_points': [min(all_entries)],  # Lowest entry
                    'exit_points': [min(all_exits)],  # Lowest exit (first target)
                    'stop_loss': min(all_stops),  # Most conservative stop
                    'risk_reward': None,
                }

                # Calculate risk/reward if possible
                entry = best_long['entry_points'][0]
                exit_point = best_long['exit_points'][0]
                stop = best_long['stop_loss']

                if entry and stop and exit_point:
                    risk = abs(entry - stop)
                    reward = abs(exit_point - entry)
                    if risk > 0:
                        best_long['risk_reward'] = round(reward / risk, 2)

                consolidated_signals.append(best_long)

        # Consolidate short signals
        if short_signals:
            # For short positions, use highest entry and highest exit (lowest price)
            all_entries = [entry for signal in short_signals for entry in signal['entry_points']]
            all_exits = [
                exit_point for signal in short_signals for exit_point in signal['exit_points']
            ]
            all_stops = [
                signal['stop_loss'] for signal in short_signals if signal['stop_loss'] is not None
            ]

            if all_entries and all_exits and all_stops:
                best_short = {
                    'direction': 'short',
                    'entry_points': [max(all_entries)],  # Highest entry
                    'exit_points': [max(all_exits)],  # Highest exit (first target)
                    'stop_loss': max(all_stops),  # Most conservative stop
                    'risk_reward': None,
                }

                # Calculate risk/reward if possible
                entry = best_short['entry_points'][0]
                exit_point = best_short['exit_points'][0]
                stop = best_short['stop_loss']

                if entry and stop and exit_point:
                    risk = abs(entry - stop)
                    reward = abs(exit_point - entry)
                    if risk > 0:
                        best_short['risk_reward'] = round(reward / risk, 2)

                consolidated_signals.append(best_short)

        return consolidated_signals

    def process_analysis(
        self,
        text: str,
        save_to_file: bool = False,
        file_path: Optional[str] = None,
        consolidate: bool = False,
    ) -> Dict[str, Any]:
        """
        Process analysis text and return JSON results

        Args:
            text: Technical analysis text
            save_to_file: Whether to save the results to a JSON file
            file_path: Path to save the JSON file (if None, generates a timestamp-based name)
            consolidate: Whether to consolidate multiple signals of the same direction

        Returns:
            Dictionary with extraction results
        """
        # Extract signals
        signals = self.extract_signals(text)

        # Consolidate signals if requested
        if consolidate:
            signals = self.consolidate_signals(signals)

        # Create results dictionary
        results = {'signals': signals, 'count': len(signals), 'timestamp': self._get_timestamp()}

        # Save to file if requested
        if save_to_file:
            self._save_to_file(results, file_path)

        return results

    def _get_timestamp(self) -> str:
        """Get current timestamp string"""
        from datetime import datetime

        return datetime.now().isoformat()

    def _save_to_file(self, data: Dict[str, Any], file_path: Optional[str] = None) -> str:
        """
        Save data to JSON file

        Args:
            data: Data to save
            file_path: Path to save file (generates one if None)

        Returns:
            Path to saved file
        """
        if file_path is None:
            from datetime import datetime

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            os.makedirs('trading_signals', exist_ok=True)
            file_path = f"trading_signals/signals_{timestamp}.json"

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        return file_path

    def extract_to_json_string(self, text: str, pretty: bool = True, consolidate: bool = False):
        """
        Extract trading signals and return as JSON string

        Args:
            text: Technical analysis text
            pretty: Whether to format the JSON with indentation
            consolidate: Whether to consolidate multiple signals of the same direction

        Returns:
            JSON string of extracted signals
        """
        raw_signals = self.extract_signals(text)

        signals = None

        # Consolidate signals if requested
        if consolidate:
            signals = self.consolidate_signals(raw_signals)

        return raw_signals, signals


# Example usage
if __name__ == '__main__':
    # Example analysis text
    analysis_text = """
    ğŸ“Œ 1. å¸ç§èƒŒæ™¯
    WLD/USDT äº 2023-07-24 ä¸Šçº¿ï¼Œæˆªè‡³ 2025-03-12ï¼Œå·²ä¸Šçº¿çº¦ 1.5 å¹´ã€‚è¯¥å¸ç§ä»å¤„äºå‘å±•é˜¶æ®µï¼Œå¸‚åœºæˆç†Ÿåº¦ä¸­ç­‰ï¼ŒæµåŠ¨æ€§é€æ­¥å¢å¼ºï¼ˆæ—¥æˆäº¤é‡åœ¨ 1.8 äº¿è‡³ 3.7 äº¿ USDT ä¹‹é—´ï¼‰ï¼Œä½†é•¿æœŸä»·æ ¼æ³¢åŠ¨è¾ƒå¤§ï¼ˆä» 1.01 é«˜ç‚¹è·Œè‡³ 0.70 ä½ç‚¹ï¼‰ã€‚è¿‘æœŸä»·æ ¼å¤„äºå†å²ä½ä½ï¼ˆ0.70â€“0.83ï¼‰ï¼Œå¯èƒ½å¸å¼•çŸ­æœŸæŠ•æœºèµ„é‡‘ï¼Œä½†å°šæœªå½¢æˆæ˜ç¡®é•¿æœŸè¶‹åŠ¿ã€‚
    ğŸ“Œ 2. å¤šæ—¶é—´å‘¨æœŸåˆ†æ
    ğŸ“Œ # 1Dï¼ˆæ—¥çº¿ï¼‰
    â€¢ è¶‹åŠ¿ï¼šçœ‹è·Œï¼ˆADX=43.57ï¼Œä»·æ ¼ä½äº SMA20/SMA50ï¼ŒMA æœªäº¤å‰ï¼‰ã€‚
    â€¢ åŠ¨èƒ½ï¼šRSIï¼ˆ33ï¼‰è¶…å–ä½†æœªåè½¬ï¼ŒMACD è´Ÿå€¼ä¸”æœªé‡‘å‰ï¼ŒçŸ­æœŸåå¼¹å¯èƒ½ä¸ºæŠ€æœ¯æ€§ä¿®å¤ã€‚
    â€¢ æ³¢åŠ¨æ€§ï¼šä»·æ ¼ä½äºå¸ƒæ—å¸¦ä¸­è½¨ä¸‹æ–¹ï¼Œä½†å·²è„±ç¦»ä¸‹è½¨ï¼Œä¸‹è¡Œç©ºé—´æ”¶çª„ã€‚
    â€¢ å†²çªç‚¹ï¼šè¶…å–ä¿¡å·ï¼ˆRSIã€Stochï¼‰ä¸ä»·æ ¼ä¸‹è¡Œè¶‹åŠ¿å¹¶å­˜ï¼Œéœ€è­¦æƒ•åå¼¹é£é™©ã€‚
    ğŸ“Œ # 4Hï¼ˆ4 å°æ—¶çº¿ï¼‰
    â€¢ è¶‹åŠ¿ï¼šä¸­æ€§ï¼ˆADX=43.08ï¼Œä»·æ ¼çªç ´ SMA20 ä½†æœªç«™ç¨³ï¼‰ã€‚
    â€¢ åŠ¨èƒ½ï¼šRSIï¼ˆ46.6ï¼‰ä¸­æ€§åå¼ºï¼ŒMACD é‡‘å‰ä¸”æŸ±çŠ¶å›¾è½¬æ­£ï¼ŒçŸ­æœŸåå¼¹ä¿¡å·ã€‚
    â€¢ å…³é”®é˜»åŠ›ï¼š0.83ï¼ˆè¿‘æœŸé«˜ç‚¹ï¼‰ï¼Œçªç ´å¯èƒ½è§¦å‘ç©ºå¤´å›è¡¥ã€‚
    ğŸ“Œ # 1Hï¼ˆå°æ—¶çº¿ï¼‰
    â€¢ è¶‹åŠ¿ï¼šçœ‹æ¶¨ï¼ˆä»·æ ¼é«˜äº SMA20/SMA50ï¼ŒADX=16.52 æ˜¾ç¤ºè¶‹åŠ¿è¾ƒå¼±ï¼‰ã€‚
    â€¢ åŠ¨èƒ½ï¼šRSIï¼ˆ59ï¼‰ã€Stochï¼ˆ76/57ï¼‰ã€CCIï¼ˆ141ï¼‰æ˜¾ç¤ºè¶…ä¹°ï¼Œä½† MACD é‡‘å‰å»¶ç»­ã€‚
    â€¢ æ³¢åŠ¨æ€§ï¼šä»·æ ¼è§¦åŠå¸ƒæ—å¸¦ä¸Šè½¨ï¼ˆ0.8295ï¼‰ï¼Œéœ€å…³æ³¨å›è°ƒé£é™©ã€‚
    ğŸ“Œ # 15mï¼ˆ15 åˆ†é’Ÿçº¿ï¼‰
    â€¢ è¶‹åŠ¿ï¼šä¸­æ€§ï¼ˆADX=24.93ï¼Œä»·æ ¼çŸ­æš‚çªç ´å¸ƒæ—å¸¦ä¸Šè½¨åå›è½ï¼‰ã€‚
    â€¢ åŠ¨èƒ½ï¼šRSIï¼ˆ72ï¼‰ã€Stochï¼ˆ92/91ï¼‰ä¸¥é‡è¶…ä¹°ï¼ŒCCIï¼ˆ139ï¼‰èƒŒç¦»ï¼ŒçŸ­æœŸå›è°ƒæ¦‚ç‡é«˜ã€‚
    ä¿¡å·ä¸€è‡´æ€§ï¼š
    â€¢ é•¿æœŸï¼ˆ1Dï¼‰çœ‹è·Œ vs çŸ­æœŸï¼ˆ1H/4Hï¼‰åå¼¹ï¼šæ—¥çº¿ä¸»å¯¼è¶‹åŠ¿ï¼Œä½†çŸ­æœŸå­˜åœ¨è¶…è·Œåå¼¹åŠ¨èƒ½ã€‚
    â€¢ è¶…ä¹°å†²çªï¼š1H/15m æ˜¾ç¤ºè¶…ä¹°ï¼Œä½† 4H åŠ¨èƒ½å°šæœªè€—å°½ï¼Œéœ€å…³æ³¨å…³é”®é˜»åŠ›ä½çªç ´æƒ…å†µã€‚
    ğŸ“Œ 3. äº¤æ˜“æœºä¼šè¯„ä¼°
    â€¢ åšå¤šæœºä¼šï¼šçŸ­æœŸï¼ˆ1H/4Hï¼‰åå¼¹ä¿¡å·æ˜ç¡®ï¼Œä½†éœ€çªç ´ 0.83 é˜»åŠ›ç¡®è®¤è¶‹åŠ¿åè½¬ã€‚
    â€¢ åšç©ºæœºä¼šï¼šè‹¥ä»·æ ¼åœ¨ 0.83 é™„è¿‘å—é˜»ï¼Œç»“åˆ 15m è¶…ä¹°ä¿¡å·å¯è½»ä»“è¯•ç©ºã€‚
    â€¢ æœ€å¼ºä¿¡å·ï¼š1H å‘¨æœŸï¼ˆRSI/CCI/MACD å…±æŒ¯çœ‹æ¶¨ï¼‰ï¼Œä½†éœ€è­¦æƒ•æ—¥çº¿è¶‹åŠ¿å‹åˆ¶ã€‚
    ğŸ“Œ 4. å…¥åœºå»ºè®®
    ğŸ“Œ # åšå¤šç­–ç•¥ï¼ˆçŸ­çº¿ï¼‰
    â€¢ å…¥åœºæ—¶æœºï¼š
    â€¢ 1Hï¼šä»·æ ¼å›è°ƒè‡³ 0.80ï¼ˆå¸ƒæ—å¸¦ä¸­è½¨/SMA20ï¼‰æˆ–çªç ´ 0.83 åå›è¸©ç¡®è®¤ã€‚
    â€¢ 4Hï¼šMACD æŸ±çŠ¶å›¾æŒç»­æ‰©å¤§ä¸”ç«™ç¨³ SMA20ï¼ˆ0.8098ï¼‰ã€‚
    â€¢ ä»·æ ¼æ°´å¹³ï¼š0.80â€“0.81ï¼ˆæ”¯æ’‘åŒºï¼‰ï¼Œ0.83ï¼ˆçªç ´è¿½å¤šï¼‰ã€‚
    ğŸ“Œ # åšç©ºç­–ç•¥ï¼ˆä¿å®ˆï¼‰
    â€¢ å…¥åœºæ—¶æœºï¼šä»·æ ¼åœ¨ 0.83 é™„è¿‘å‡ºç° 15m çœ‹è·Œä¿¡å·ï¼ˆå¦‚é•¿ä¸Šå½±çº¿ã€RSI é¡¶èƒŒç¦»ï¼‰ã€‚
    â€¢ ä»·æ ¼æ°´å¹³ï¼š0.83â€“0.84ï¼ˆé˜»åŠ›åŒºï¼‰ã€‚
    ğŸ“Œ 5. é£é™©ç®¡ç†
    â€¢ æ­¢æŸä½ï¼š
    â€¢ åšå¤šï¼š0.77ï¼ˆæ—¥çº¿å‰ä½ä¸‹æ–¹ï¼‰ã€‚
    â€¢ åšç©ºï¼š0.85ï¼ˆçªç ´è¿‘æœŸé«˜ç‚¹ï¼‰ã€‚
    â€¢ æ­¢ç›ˆç›®æ ‡ï¼š
    â€¢ åšå¤šï¼š0.88ï¼ˆ4H å‰é«˜ï¼‰ã€0.95ï¼ˆæ—¥çº¿ä¸­è½¨ï¼‰ã€‚
    â€¢ åšç©ºï¼š0.75ï¼ˆ4H æ”¯æ’‘ï¼‰ã€0.70ï¼ˆå¿ƒç†å…³å£ï¼‰ã€‚
    ğŸ“Œ 6. ä¿¡å·å†²çªè§£é‡Š
    â€¢ æ—¥çº¿ vs å°æ—¶çº¿ï¼šæ—¥çº¿é•¿æœŸè¶…å–æœªåè½¬ï¼Œä½†çŸ­æœŸèµ„é‡‘æ¶Œå…¥æ¨å‡ä»·æ ¼ï¼Œå½¢æˆæŠ€æœ¯æ€§åå¼¹ã€‚
    â€¢ 1H è¶…ä¹° vs 4H ä¸­æ€§ï¼š1H è¶…ä¹°å¯èƒ½å¼•å‘å›è°ƒï¼Œä½† 4H åŠ¨èƒ½å°šæœªè€—å°½ï¼Œéœ€è§‚å¯Ÿä»·æ ¼èƒ½å¦ç«™ç¨³å…³é”®ä½ã€‚
    ğŸ“Œ æ€»ç»“ä¸äº¤æ˜“å»ºè®®
    å½“å‰è§‚ç‚¹ï¼šçŸ­æœŸåå¼¹åŠ¨èƒ½å­˜åœ¨ï¼Œä½†æ—¥çº¿è¶‹åŠ¿å‹åˆ¶æ˜æ˜¾ï¼Œå»ºè®®ä»¥çŸ­çº¿åšå¤šä¸ºä¸»ï¼Œä¸¥æ ¼æ­¢æŸã€‚
    æœ€ç»ˆå»ºè®®ï¼š
    â€¢ åšå¤šï¼šåœ¨ 0.80â€“0.81 åŒºé—´è½»ä»“å…¥åœºï¼Œæ­¢æŸ 0.77ï¼Œç›®æ ‡ 0.88ã€‚
    â€¢ æ¿€è¿›è¿½å¤šï¼šè‹¥æ”¾é‡çªç ´ 0.83ï¼Œå›è¸© 0.82 åŠ ä»“ï¼Œæ­¢æŸ 0.79ã€‚
    â€¢ åšç©ºï¼šä»…åœ¨ 0.83 é™„è¿‘å‡ºç°æ˜ç¡®åè½¬ä¿¡å·åè¯•ç©ºï¼Œæ­¢æŸ 0.85ã€‚
    åŠ ç²—ç»“è®ºï¼šçŸ­çº¿çœ‹æ¶¨ï¼Œä½†éœ€ä¸¥æ ¼æ­¢æŸï¼›æ—¥çº¿è¶‹åŠ¿æœªåè½¬å‰ï¼Œé¿å…é‡ä»“æŒæœ‰ã€‚
    """

    # Initialize extractor
    extractor = TradingSignalExtractor()

    # Extract signals and print as JSON
    # print("Original signals:")
    # json_output = extractor.extract_to_json_string(analysis_text)
    # print(json_output)

    # Extract signals, consolidate, and print as JSON
    print('\nConsolidated signals:')
    json_output = extractor.extract_to_json_string(analysis_text, consolidate=True)
    print(json_output)
